# AI-Assisted LaTeX & Lab Report Grading

## Project Summary

The AI-Assisted LaTeX & Lab Report Grading project focuses on using AI to support instructors in evaluating complex, technical student submissions while preserving human judgment and instructional intent. The system is designed to assist with the review of LaTeX-based lab reports, code outputs, and technical explanations by generating structured, editable feedback aligned with instructor-defined criteria.

This project directly supports the BOBPE goal of productivity enhancement by reducing the time required for routine evaluation tasks, enabling instructors to scale high-quality feedback without compromising rigor or fairness.

---

## Educational Problem Addressed

Evaluating technical lab reports is one of the most time-intensive components of engineering instruction. In large enrollment courses, instructors must balance consistency, depth of feedback, and grading turnaround time, often at the expense of one or more of these priorities.

Traditional grading workflows make it difficult to provide detailed formative feedback at scale, limiting opportunities for students to learn from their mistakes and refine their understanding.

---

## How AI Is Used

AI is used to:
- Parse LaTeX-based lab reports and associated code outputs
- Generate draft evaluations aligned with rubrics and learning objectives
- Highlight areas of strength, misunderstanding, or omission
- Provide structured, criterion-based feedback for instructor review
- Support consistency across multiple graders and sections

All AI-generated evaluations are editable and subject to instructor approval prior to release.

---

## Human-in-the-Loop Workflow

The grading workflow explicitly preserves instructor oversight:

1. Student submissions are compiled and rendered for review.
2. The AI generates a draft evaluation based on instructor-provided criteria.
3. Instructors or teaching staff review, edit, and finalize feedback.
4. Final grades and comments are released based on human judgment.

The AI functions as an assistive tool rather than an autonomous grader.

---

## Instructor Experience and Scale

This system has been designed with large courses in mind and supports:
- High enrollment classes with many lab sections
- Multiple graders requiring consistent evaluation standards
- Rapid feedback cycles without sacrificing quality

By offloading routine analysis and drafting tasks, instructors can devote more time to higher-level feedback and instructional design.

---

## Limitations and Guardrails

- The system does not assign final grades independently
- Instructor-provided rubrics and criteria are required
- Outputs must be reviewed for correctness and appropriateness
- Privacy and data handling considerations are explicitly addressed

These guardrails ensure responsible and ethical use of AI in assessment contexts.

---

## Deployment Status

**Status:** Active classroom use / Ongoing development  
The system has been deployed in instructional settings and continues to evolve based on course scale, assignment complexity, and instructor feedback.

---

## Artifacts and Links

- GitHub repository:  
  https://github.com/hodgkinr/BOBPE-latex-grader

- Interface demos and walkthroughs:  
  https://drive.google.com/drive/folders/1b_LiiZ1RC0O6c_g5snVK5EFxVZ_Fxn3o

- Example UI video:  
  `latex_grader.mov` (linked in demo materials)

---

## Alignment with BOBPE Mission

This project exemplifies the productivity enhancement dimension of BOBPE by enabling instructors to scale meaningful, timely feedback while preserving human oversight. It demonstrates how AI can be responsibly integrated into assessment workflows to support both instructional quality and instructor sustainability.
